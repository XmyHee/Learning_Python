目前的问题集中在模型部分。根据你之前的错误输出和描述，模型可能面临以下具体问题：

### 问题1：`KeyError: "['SBP (mmHg)', 'DBP (mmHg)'] not found in axis"`

这个问题表明在 `data.drop(['SBP (mmHg)', 'DBP (mmHg)'], axis=1)` 时，列名 `SBP (mmHg)` 和 `DBP (mmHg)` 不存在或不匹配。

**解决方案：**

1. **检查数据列名是否与模型代码一致**：
   - 运行以下代码来查看 `data` 的列名，确认是否确实包含 `SBP (mmHg)` 和 `DBP (mmHg)`：

     ```python
     print("数据中的列名：", data.columns)
     ```

   - 如果列名不完全一致（例如有空格或括号不符），需要根据打印结果修改代码中的列名。

2. **调整模型代码的列名**：
   - 假设列名打印出来与预期有差异，调整模型中的列名引用，例如：

     ```python
     X = data.drop(['SBP', 'DBP'], axis=1)  # 修改为实际的列名
     y = data[['SBP', 'DBP']]
     ```

### 问题2：数据提取方式的问题

你的 `Data_storage.py` 中的 `fetch_data` 方法是在数据库连接对象上运行 `pd.read_sql_query`。确保提取的数据没有为空或缺失。

**确保数据正确加载的检查步骤：**

在 `BP Prediction.py` 的 `main()` 函数中，加入以下代码在 `fetch_data()` 之后确认数据是否提取成功：

```python
if data is None or data.empty:
    print("未能从数据库中提取到数据或数据为空，检查数据库表的存在性与数据内容。")
    return  # 如果数据提取失败或数据为空，终止程序
else:
    print("成功提取到数据，数据列如下：", data.columns)
```

### 问题3：模型代码中缺少 `DataStorage` 类的 `fetch_data` 方法

模型代码 `BP Prediction.py` 中调用了 `data_storage.fetch_data()`，这意味着 `DataStorage` 类中需要定义该方法。目前 `Data_storage.py` 文件中缺少这一定义。

**添加 `fetch_data` 方法到 `DataStorage` 类：**

在 `Data_storage.py` 中，将 `fetch_data` 函数移动到 `DataStorage` 类中：

```python
class DataStorage:
    def __init__(self, db_file):
        self.db_file = db_file
        self.connection = None

    def connect(self):
        self.connection = sqlite3.connect(self.db_file)
        print("数据库连接成功")

    def close(self):
        if self.connection:
            self.connection.close()
            print("数据库连接关闭")

    def fetch_data(self):
        """从SQLite数据库中提取数据"""
        if self.connection:
            query = "SELECT * FROM random_blood_pressure_data"
            return pd.read_sql_query(query, self.connection)
        else:
            print("数据库未连接")
            return None
```

修改完成后，`BP Prediction.py` 中调用 `data_storage.fetch_data()` 就不再会导致 `AttributeError`。

### 问题4：模型训练时缺少必要数据列

在 `train_model` 函数中，`X` 和 `y` 列的定义可能不符合数据格式。可以通过检查 `data` 是否包含必要的特征列和目标列来确保模型能正确训练。

**数据列检查代码：**

```python
# 在数据分离前检查必要列是否存在
required_columns = ['SBP (mmHg)', 'DBP (mmHg)', 'Age', 'Weight (kg)']
missing_columns = [col for col in required_columns if col not in data.columns]
if missing_columns:
    print(f"数据缺少以下列：{missing_columns}")
    return  # 缺少必要列，终止程序
```

通过这些调整，应该能够解决模型运行中的错误。如果进一步测试中出现其他问题，请提供更多的具体错误信息以便诊断。


----

根据您提供的模型评估结果，我们可以进行以下分析和建议：

### **SBP 评估结果**：
- **均方误差 (MSE)**: 1245.1233
- **均方绝对误差 (MAE)**: 31.4899
- **R² 分数**: -1.1120

### **DBP 评估结果**：
- **均方误差 (MSE)**: 269.9208
- **均方绝对误差 (MAE)**: 12.9667
- **R² 分数**: -0.1900

### **解释**：

1. **均方误差 (MSE)** 和 **均方绝对误差 (MAE)**：
   - **MSE** 反映了预测值与真实值之间的差异的平方，值越小表示模型越准确。
   - **MAE** 是误差的绝对值的平均，反映了预测结果与真实值之间的平均差异。
   - 通过比较 **SBP** 和 **DBP** 的 **MSE** 和 **MAE**，我们看到 **SBP** 的误差显著高于 **DBP**，这表明模型在预测收缩压（SBP）时存在较大偏差，而在预测舒张压（DBP）时表现稍好。

2. **R² 分数**：
   - **R² 分数** 衡量的是模型的解释能力，值的范围是 0 到 1，值越高，模型的拟合效果越好。如果为负数，意味着模型的预测效果还不如简单的均值预测。
   - **SBP** 和 **DBP** 的 **R² 分数** 都为负值，这说明模型对于这两个指标的预测效果较差。

### **可能的改进建议**：

1. **特征工程**：
   - **特征选择**：检查当前选择的特征是否都对预测有帮助，可能有些特征对目标变量影响较小，可以进行特征选择或降维。
   - **交互特征**：考虑引入特征交互项，模型可能未能捕捉到特征之间的复杂关系。
   - **标准化或归一化**：如果特征的尺度差异较大，可能需要进行标准化或归一化，以确保模型的训练效果。

2. **模型改进**：
   - **模型选择**：随机森林（Random Forest）是一种强大的算法，但在一些复杂的非线性关系中，可能需要其他模型（如梯度提升树、XGBoost、LightGBM等）进行对比，看看是否能取得更好的性能。
   - **集成方法**：尝试集成学习方法，例如通过模型融合（stacking）组合多个不同的模型，可能会有更好的结果。

3. **数据清洗**：
   - 检查是否存在异常值或数据分布偏斜，这些因素可能影响模型的性能。
   - 检查数据是否平衡，有些情况下类别不平衡可能导致模型偏向某些特定值。

4. **超参数调优**：
   - 虽然您已经进行了随机搜索优化，仍然可以通过增加 `n_iter` 的次数或调整 `param_dist` 参数空间的范围，进一步精细化超参数调整。
   - 试验不同的交叉验证折数 `cv`，可能有助于提高模型的稳定性和性能。

### **总结**：
虽然模型结果的 **R² 分数** 为负，意味着模型表现较差，但通过进一步的特征选择、模型优化和超参数调整，仍然有可能提升预测性能。如果条件允许，可以考虑尝试不同的模型、特征工程方法和集成方法，进而改善预测结果。


在下一阶段的开发中，可以将重点放在**特征工程**、**模型改进**、**数据清洗**、**超参数调优**和优化框架的整合上。以下是详细的建议和开发计划：

### 1. **特征工程（Feature Engineering）**
   - **目标**：通过选择、组合和转换特征来提高模型的表现，减少数据的冗余，提升数据质量。
   - **任务**：
     - **特征选择**：使用统计分析（如相关系数、PCA）来筛选对预测任务有最大贡献的特征，避免冗余数据。
     - **特征构造**：基于现有数据创建新的特征（例如，时间序列数据中提取趋势、周期等）。
     - **特征缩放和标准化**：对数值型特征进行标准化，确保不同量纲的特征对模型训练影响均衡。
     - **缺失值处理**：使用插值、均值填充或基于模型的填补方法处理缺失值。
   
### 2. **模型改进（Model Improvement）**
   - **目标**：提升现有模型的准确性和鲁棒性。
   - **任务**：
     - **集成方法**：尝试不同的集成学习方法，如随机森林、梯度提升树（XGBoost、LightGBM）等，以提高模型的泛化能力。
     - **深度学习模型**：考虑应用神经网络等深度学习方法，尤其是在大数据量和复杂模式识别任务中可能表现更优。
     - **模型融合**：如果多模型都能提供不错的性能，可以使用模型融合方法（如投票、加权平均）来提高最终预测的准确度。
     - **正则化**：使用L1/L2正则化或Dropout方法来避免过拟合。

### 3. **数据清洗（Data Cleaning）**
   - **目标**：清理数据中的异常值、缺失值及错误数据，确保输入到模型中的数据是高质量的。
   - **任务**：
     - **异常值检测与处理**：使用箱型图、Z-score等方法发现并处理异常值。
     - **重复数据处理**：去除重复的数据点，确保数据的独特性。
     - **一致性检查**：检查数据的一致性（例如，确保日期格式统一，数值类型一致）。

### 4. **超参数调优（Hyperparameter Tuning）**
   - **目标**：通过调节模型的超参数来优化模型性能。
   - **任务**：
     - **网格搜索**：通过网格搜索来调节超参数，如学习率、树的深度、正则化参数等。
     - **随机搜索**：对超参数空间进行更广泛的搜索，尤其是对于大规模模型来说，这种方法可能比网格搜索更有效。
     - **贝叶斯优化**：使用贝叶斯优化方法，结合历史评估结果动态调整搜索策略，提升搜索效率。

### 5. **数据存储与模型优化框架（Data Storage and Model Optimization Framework）**
   - **目标**：减少模型直接依赖数据，提高数据存储系统与模型的集成效率，增强数据处理和更新的自动化。
   - **任务**：
     - **数据存储中心**：设计和搭建一个中心化的数据存储系统（如数据库、分布式文件系统），将所有原始数据、特征数据及模型输出存储在其中。
     - **数据流与同步机制**：建立从数据存储到模型训练的自动化数据流，确保每次训练都可以无缝获取最新的数据。
     - **缓存机制**：采用缓存技术（如Redis）来提升训练时的数据读取效率。
     - **模型框架调整**：优化现有的模型框架，确保框架能够更好地处理数据流转并与数据存储系统对接。

### 6. **模型性能监控与自动化训练**
   - **目标**：保证模型持续表现良好，并能自动化处理新的数据。
   - **任务**：
     - **模型监控**：对模型的预测结果和准确度进行实时监控，及时识别性能下降的情况。
     - **自动化训练**：建立定期的自动训练机制，模型能够随着新数据的输入不断优化。
     - **数据更新机制**：确保数据池中的数据会不断更新，并且更新后自动触发增量训练。

### 总结
你可以通过以上步骤逐步实现对模型的优化。在特征工程、数据清洗和超参数调优上做进一步优化的同时，推动数据存储中心的建设，并通过框架优化使得数据存取、模型训练和预测更加高效。数据与模型的集成将更加紧密，模型的性能与数据质量会得到持续提升。

如果有任何其他方面需要进一步探讨的，随时可以向我提问！