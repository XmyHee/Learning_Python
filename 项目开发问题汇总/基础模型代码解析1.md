这段代码负责读取和处理CSV数据文件，设置特征和目标变量，以及训练一个简单的线性回归模型。根据你的需求，以下是如何将这段代码与新的模块化结构整合并替换的建议：

### 1. 整合模块
为了让模型自动适应数据的变化，并简化后续调用，可以将这段代码拆分为几个功能明确的函数，放置在`Data_loader.py`中：

- **数据加载**：读取CSV文件并返回数据集。
- **数据预处理**：进行数据清理、列名处理、特征和目标变量设置。
- **数据拆分**：将数据集分为训练集和测试集。

### 2. 函数示例
以下是如何将你的代码转化为函数的示例：

```python
# Data_loader.py

import pandas as pd
import os
from sklearn.model_selection import train_test_split

def load_data(file_path):
    """读取CSV文件并返回数据框"""
    if os.path.exists(file_path):
        data = pd.read_csv(file_path)
        data.columns = data.columns.str.strip()  # 去掉列名两端的空格
        return data
    else:
        raise FileNotFoundError(f"文件 {file_path} 未找到，请检查路径和文件名。")

def preprocess_data(data):
    """预处理数据，返回特征和目标变量"""
    # 将中文列名替换成英文列名（如果需要）
    data = data.rename(columns={
        '年龄': 'Age',
        '体重': 'Weight (kg)',
        '收缩压': 'SBP (mmHg)',
        '舒张压': 'DBP (mmHg)'
    })
    
    # 设置特征和目标变量
    required_columns = ['Age', 'Weight (kg)', 'SBP (mmHg)', 'DBP (mmHg)'] 
    if not all(col in data.columns for col in required_columns):
        raise ValueError("数据中缺少必要的列，请检查数据文件。")
    
    X = data[['Age', 'Weight (kg)']]
    y = data['SBP (mmHg)']
    
    # 确保数据类型正确并删除缺失值
    X = X.apply(pd.to_numeric, errors='coerce')
    y = pd.to_numeric(y, errors='coerce')
    X = X.dropna()
    y = y[X.index]
    
    return X, y

def split_data(X, y, test_size=0.2, random_state=42):
    """拆分数据集"""
    return train_test_split(X, y, test_size=test_size, random_state=random_state)
```

### 3. 在主程序中调用
在你的`main.py`中，你可以这样调用上述函数：

```python
# main.py
from Data_loader import load_data, preprocess_data, split_data

# 1. 读取 CSV 文件
input_dir = r"D:\测试项目\pythonProject\blood_pressure_data"
data_file = os.path.join(input_dir, "cleaned_blood_pressure_data.csv")  
all_data = load_data(data_file)

# 2. 预处理数据
X, y = preprocess_data(all_data)

# 3. 拆分数据集
X_train, X_test, y_train, y_test = split_data(X, y)

# 4. 进行模型训练和评估（这里你可以调用 BP_Prediction.py 中的代码）
```

### 4. 代码分层结构
在此结构中，`Data_loader.py` 负责数据的加载与预处理，而 `BP_Prediction.py` 则集中处理模型的训练与评估。这样，每当数据变动时，你只需确保 `Data_loader.py` 的读取逻辑是最新的，而 `BP_Prediction.py` 中的模型不需要频繁修改，提升了代码的可维护性。

请根据以上建议修改你的代码结构，以提高代码的灵活性和可读性。

---
第二段代码主要负责加载数据、处理特征和目标变量、训练模型、进行预测以及评估模型的性能。在将其整合进模块化结构时，我们可以进一步拆分这个过程，将各个步骤封装成函数，并将其放入相应的模块中。以下是整合建议：

### 1. 整合模块
为了提高代码的复用性和可维护性，可以将以下功能分成几个函数：

- **数据加载和准备**：读取CSV文件并返回清洗后的数据。
- **模型训练**：创建模型、训练和预测。
- **结果可视化**：可视化实际值与预测值的对比。

### 2. 函数示例
以下是如何将第二段代码转化为函数的示例：

```python
# Data_loader.py
import pandas as pd
import os

def load_and_prepare_data(input_dir):
    """加载并准备数据"""
    file_path = os.path.join(input_dir, "blood_pressure_data.csv")
    try:
        data = pd.read_csv(file_path)
        data.columns = data.columns.str.strip()  # 去除列名两端的空格
        print("成功读取的文件:")
        print(data.head())
        print("数据列名:")
        print(data.columns.tolist())  # 打印列名
        return data
    except FileNotFoundError:
        print("blood_pressure_data.csv 文件未找到。")
        return None
```

```python
# BP_Prediction.py
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error
import matplotlib.pyplot as plt

def train_and_evaluate_model(data):
    """训练模型并评估"""
    try:
        X = data[['Age', 'Weight (kg)']]
        y = data['SBP (mmHg)']
    except KeyError as e:
        print(f"错误: {e}. 请检查列名是否正确。")
        raise

    # 拆分数据集
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    # 创建并训练线性回归模型
    model = LinearRegression()
    model.fit(X_train, y_train)

    # 进行预测
    y_pred = model.predict(X_test)

    # 评估模型
    mse = mean_squared_error(y_test, y_pred)
    print(f"均方误差: {mse}")

    return y_test, y_pred

def visualize_results(y_test, y_pred):
    """可视化实际值与预测值的对比"""
    plt.figure(figsize=(10, 6))
    plt.scatter(y_test, y_pred, alpha=0.7, label='预测值')
    plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', linestyle='--', label='参考线')
    plt.xlabel('实际值')
    plt.ylabel('预测值')
    plt.title('实际值与预测值对比')
    plt.grid(True)
    plt.legend()
    plt.show()
```

### 3. 在主程序中调用
在你的`main.py`中，可以按照以下方式调用这些函数：

```python
# main.py
from Data_loader import load_and_prepare_data
from BP_Prediction import train_and_evaluate_model, visualize_results

# 输入目录
input_dir = r"D:\测试项目\pythonProject\blood_pressure_data"

# 1. 加载数据
data = load_and_prepare_data(input_dir)

if data is not None:
    # 2. 训练模型并评估
    y_test, y_pred = train_and_evaluate_model(data)

    # 3. 可视化结果
    visualize_results(y_test, y_pred)
```

### 4. 代码结构
通过这种方式，数据加载、模型训练和评估、结果可视化被清晰地分离成独立的函数。这样的结构使得代码更易于维护和扩展，同时也便于后续的调试和修改。

### 总结
通过将第二段代码模块化，我们可以提高代码的清晰度和灵活性，便于处理未来可能的数据变化。希望这个整合建议能帮助你构建一个更高效、可维护的模型！

---
第三段代码主要执行数据加载、模型训练、预测以及结果的可视化。为了提高代码的可重用性和可维护性，建议将其结构化，并将各个功能封装为独立的函数。此外，我们可以将数据加载、模型训练和可视化部分放在不同的模块中。以下是如何实现这一点的详细步骤：

### 1. 模块化结构

我们可以将以下功能拆分为独立的函数：

- **数据加载**：读取并返回数据。
- **模型训练和预测**：训练模型并返回预测结果。
- **结果可视化**：展示实际值与预测值的对比。

### 2. 函数示例

以下是将第三段代码转化为模块化结构的示例：

```python
# Data_loader.py
import pandas as pd
import os

def load_data(input_dir):
    """加载并准备数据"""
    file_path = os.path.join(input_dir, "blood_pressure_data.csv")
    try:
        data = pd.read_csv(file_path)
        print("成功读取的文件:")
        print(data.head())  # 输出前几行数据以确认读取成功
        return data
    except FileNotFoundError:
        print("blood_pressure_data.csv 文件未找到。")
        return None
    except Exception as e:
        print(f"读取文件 {file_path} 时发生错误: {e}")
        return None
```

```python
# BP_Prediction.py
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error
import pandas as pd

def train_and_predict(data):
    """训练线性回归模型并进行预测"""
    required_columns = ['Age', 'Weight (kg)', 'SBP (mmHg)']
    if not all(col in data.columns for col in required_columns):
        print(f"数据中缺少必要的列: {set(required_columns) - set(data.columns)}")
        return None, None

    X = data[['Age', 'Weight (kg)']]
    y = data['SBP (mmHg)']

    # 拆分数据集
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    # 创建并训练模型
    model = LinearRegression()
    model.fit(X_train, y_train)

    # 进行预测
    y_pred = model.predict(X_test)

    # 计算均方误差
    mse = mean_squared_error(y_test, y_pred)
    print(f"均方误差: {mse}")

    # 打印实际值与预测值的对比
    results = pd.DataFrame({'实际值': y_test, '预测值': y_pred})
    print(results)

    return y_test, y_pred
```

```python
# Visualizer.py
import matplotlib.pyplot as plt

def visualize_results(y_test, y_pred):
    """可视化实际值与预测值的对比"""
    plt.figure(figsize=(10, 6))
    plt.scatter(y_test, y_pred, alpha=0.7, label='预测值')
    plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', linestyle='--', label='参考线')  # 参考线
    plt.xlabel('实际值')
    plt.ylabel('预测值')
    plt.title('实际值与预测值对比')
    plt.grid(True)
    plt.legend()
    plt.show()
```

### 3. 在主程序中调用

在`main.py`中，你可以按以下方式调用这些函数：

```python
# main.py
from Data_loader import load_data
from BP_Prediction import train_and_predict
from Visualizer import visualize_results

def main():
    # 设置文件夹路径
    input_dir = r"D:\测试项目\pythonProject\blood_pressure_data"
    data = load_data(input_dir)  # 使用新的 load_data 函数

    if data is None:
        return  # 如果没有数据，终止程序

    # 训练模型并进行预测
    y_test, y_pred = train_and_predict(data)

    if y_test is not None and y_pred is not None:
        # 可视化结果
        visualize_results(y_test, y_pred)

if __name__ == "__main__":
    main()
```

### 4. 代码结构

通过将各个部分拆分成独立的模块，代码不仅更加清晰，也更容易进行调试和维护。这种模块化设计可以提高代码的可读性和可重用性。

### 总结

通过上述重构，你的代码现在采用模块化设计，功能分明，有助于后续的扩展和优化。希望这些改进能够帮助你在开发中更加高效！如果你有任何问题或需要进一步的帮助，请随时告知！

---
第四段代码用于模型评估，通过计算多种评估指标来衡量模型的性能，包括均方误差（MSE）、平均绝对误差（MAE）和决定系数（R²）。这些指标能够为模型预测的准确性提供重要的参考。以下是代码的详细解析及如何优化的建议：

### 1. 功能分析

该段代码的功能分为几个部分：

- **引入必要的库**：导入用于计算评估指标的函数。
- **设置真实值和预测值**：以假设的数据为例。
- **计算评估指标**：使用相应的函数计算MSE、MAE和R²。
- **输出结果**：打印计算结果，方便进行分析。

### 2. 代码优化建议

为了使代码更具可读性和可重用性，可以考虑将评估过程封装到一个函数中。这种方式有助于在将来的模型评估中更方便地调用，并且代码逻辑更加清晰。

以下是将第四段代码进行封装后的示例：

```python
# Evaluation.py
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

def evaluate_model(y_true, y_pred):
    """计算并打印模型评估指标"""
    mse = mean_squared_error(y_true, y_pred)  # 均方误差
    mae = mean_absolute_error(y_true, y_pred)  # 平均绝对误差
    r2 = r2_score(y_true, y_pred)  # 决定系数

    # 打印评估结果
    print(f"Mean Squared Error (MSE): {mse:.2f}")
    print(f"Mean Absolute Error (MAE): {mae:.2f}")
    print(f"R-squared (R²): {r2:.2f}")

# 示例数据
if __name__ == "__main__":
    # 假设实际值和预测值如下所示：
    y_true = [120, 130, 128, 132, 135]  # 真实的血压值示例
    y_pred = [118, 131, 130, 129, 136]  # 模型预测的血压值示例

    evaluate_model(y_true, y_pred)
```

### 3. 在主程序中调用

你可以在`main.py`中调用评估函数，以便在模型训练和预测后进行评估：

```python
# main.py
from Data_loader import load_data
from BP_Prediction import train_and_predict
from Visualizer import visualize_results
from Evaluation import evaluate_model

def main():
    # 设置文件夹路径
    input_dir = r"D:\测试项目\pythonProject\blood_pressure_data"
    data = load_data(input_dir)  # 使用新的 load_data 函数

    if data is None:
        return  # 如果没有数据，终止程序

    # 训练模型并进行预测
    y_test, y_pred = train_and_predict(data)

    if y_test is not None and y_pred is not None:
        # 可视化结果
        visualize_results(y_test, y_pred)

        # 进行模型评估
        evaluate_model(y_test, y_pred)

if __name__ == "__main__":
    main()
```

### 总结

通过将评估部分封装成函数，你的代码结构变得更加模块化，有助于将来进行功能扩展或维护。这种做法也使得主程序逻辑更加清晰，容易理解。

如果你有任何疑问或需要进一步帮助，请随时告诉我！

---
第五段代码用于进行残差分析，通过绘制残差图来帮助评估模型的预测效果。残差（即真实值与预测值之间的差）是检验模型性能的重要指标，残差分析可以帮助我们理解模型的不足之处以及数据是否符合线性假设。

### 1. 功能分析

- **导入库**：引入`numpy`和`matplotlib.pyplot`用于数值计算和绘图。
- **数据转换**：将真实值和预测值转换为NumPy数组，便于进行数学运算。
- **计算残差**：通过`y_true - y_pred`计算每个预测值的残差。
- **绘制残差图**：创建散点图，横坐标为预测值，纵坐标为残差，并添加零线以便于观察残差的分布。

### 2. 代码优化建议

为了提高代码的可读性和复用性，可以将残差分析封装成一个函数，方便在不同的上下文中使用。以下是改进后的示例：

```python
# Residual_analysis.py
import numpy as np
import matplotlib.pyplot as plt

def plot_residuals(y_true, y_pred):
    """绘制残差图"""
    # 将 y_true 和 y_pred 转换为 numpy 数组
    y_true = np.array(y_true)
    y_pred = np.array(y_pred)

    # 计算残差
    residuals = y_true - y_pred

    # 绘制残差图
    plt.figure(figsize=(10, 6))
    plt.scatter(y_pred, residuals, color='blue', alpha=0.6)
    plt.axhline(0, color='red', linestyle='--')  # 添加零线
    plt.xlabel("Predicted Values")
    plt.ylabel("Residuals")
    plt.title("Residual Plot")
    plt.grid()
    plt.show()

# 示例数据
if __name__ == "__main__":
    # 假设实际值和预测值如下所示：
    y_true = [120, 130, 128, 132, 135]
    y_pred = [118, 131, 130, 129, 136]

    plot_residuals(y_true, y_pred)
```

### 3. 在主程序中调用

你可以在主程序中调用该函数，进行残差分析。比如在`main.py`中，可以在模型评估之后调用该函数：

```python
# main.py
from Data_loader import load_data
from BP_Prediction import train_and_predict
from Visualizer import visualize_results
from Evaluation import evaluate_model
from Residual_analysis import plot_residuals

def main():
    # 设置文件夹路径
    input_dir = r"D:\测试项目\pythonProject\blood_pressure_data"
    data = load_data(input_dir)  # 使用新的 load_data 函数

    if data is None:
        return  # 如果没有数据，终止程序

    # 训练模型并进行预测
    y_test, y_pred = train_and_predict(data)

    if y_test is not None and y_pred is not None:
        # 可视化结果
        visualize_results(y_test, y_pred)

        # 进行模型评估
        evaluate_model(y_test, y_pred)

        # 进行残差分析
        plot_residuals(y_test, y_pred)

if __name__ == "__main__":
    main()
```

### 总结

通过将残差分析封装为一个函数，你的代码更加模块化，便于维护和扩展。残差图是检测模型性能的重要工具，合理利用将帮助你优化模型。

如果你有任何问题或需要进一步的建议，请随时联系我！

---
第六段代码展示了如何整合多个预测结果并计算最终的预测值。这在机器学习和统计分析中非常重要，因为通过多次测量或预测结果的整合，可以提高预测的稳定性和准确性。

### 1. 功能分析

- **导入库**：引入`numpy`库用于数值计算。
- **假设数据**：创建三组不同的预测结果（`y_pred_1`、`y_pred_2`和`y_pred_3`），这可能是来自于不同模型的预测结果或同一模型在不同条件下的多次预测。
- **整合预测值**：将这三组预测值整合到一个列表中，然后计算每个样本的平均预测值（`final_predictions`），或者你可以选择使用中位数进行整合。
- **输出最终预测值**：打印最终的预测值。

### 2. 代码优化建议

为了提高代码的可读性和复用性，可以将预测值整合和分析的逻辑封装为一个函数。以下是改进后的示例：

```python
# prediction_analysis.py
import numpy as np

def consolidate_predictions(predictions_list, method='mean'):
    """整合多次预测值并计算最终预测值
    参数:
    predictions_list: list of np.array - 预测值的列表
    method: str - 'mean' 或 'median', 选择整合方法

    返回:
    np.array - 最终预测值
    """
    if method == 'mean':
        return np.mean(predictions_list, axis=0)
    elif method == 'median':
        return np.median(predictions_list, axis=0)
    else:
        raise ValueError("Method must be 'mean' or 'median'.")

# 示例数据
if __name__ == "__main__":
    # 假设这是三次不同的预测结果
    y_pred_1 = np.array([118, 131, 130, 129, 136])
    y_pred_2 = np.array([119, 132, 129, 130, 134])
    y_pred_3 = np.array([117, 130, 131, 128, 137])

    # 将三组预测值整合到列表中
    predictions_list = [y_pred_1, y_pred_2, y_pred_3]

    # 计算每个样本的平均预测值
    final_predictions = consolidate_predictions(predictions_list, method='mean')
    # 或使用中位数
    # final_predictions = consolidate_predictions(predictions_list, method='median')

    print("Final Predicted Values:", final_predictions)
```

### 3. 在主程序中调用

如果在主程序中需要整合多次预测值，可以直接调用`consolidate_predictions`函数。例如，在`main.py`中可以这样做：

```python
from prediction_analysis import consolidate_predictions

def main():
    # 假设这是三次不同的预测结果
    y_pred_1 = np.array([118, 131, 130, 129, 136])
    y_pred_2 = np.array([119, 132, 129, 130, 134])
    y_pred_3 = np.array([117, 130, 131, 128, 137])

    # 将三组预测值整合到列表中
    predictions_list = [y_pred_1, y_pred_2, y_pred_3]

    # 计算每个样本的平均预测值
    final_predictions = consolidate_predictions(predictions_list, method='mean')

    print("Final Predicted Values:", final_predictions)

if __name__ == "__main__":
    main()
```

### 总结

通过整合多个预测值，你可以提高模型的鲁棒性，减少偶然误差的影响。选择使用平均值或中位数取决于数据的分布情况和需求，合理的选择将有助于提高预测的准确性。

如果你对整合分析的过程或其他相关问题有进一步的疑问，请随时联系我！

---
第七段代码实现了模型评估过程中的日志记录和错误监控，这对于后续的模型调试和性能分析至关重要。通过记录关键信息和错误，可以有效地追踪模型的表现和处理潜在的问题。

### 1. 功能分析

- **导入库**：使用`logging`库来进行日志记录。
- **设置日志配置**：
  - 指定日志文件名为`model_logs.log`。
  - 设置日志级别为`INFO`，以记录所有信息级别及以上的日志。
  - 定义日志输出格式，包括时间戳、日志级别和消息内容。
- **模型评估过程**：
  - 计算均方误差（MSE）、平均绝对误差（MAE）和决定系数（R²）。
  - 使用`logging.info()`记录评估结果，包括MSE、MAE和R²值。
- **错误处理**：
  - 使用`try-except`块捕捉在评估过程中可能发生的异常。
  - 如果发生错误，使用`logging.error()`记录错误信息，并将详细的异常信息输出到日志中。

### 2. 代码优化建议

在实际使用中，可以进一步增强日志记录的功能，比如添加更多的上下文信息。以下是改进后的示例代码：

```python
# logging_setup.py
import logging

def setup_logging(log_file='model_logs.log'):
    """设置日志记录配置"""
    logging.basicConfig(filename=log_file, level=logging.INFO,
                        format='%(asctime)s - %(levelname)s - %(message)s')

def log_model_evaluation(y_true, y_pred):
    """记录模型评估结果"""
    try:
        mse = mean_squared_error(y_true, y_pred)
        mae = mean_absolute_error(y_true, y_pred)
        r2 = r2_score(y_true, y_pred)

        # 记录评估结果
        logging.info(f"Model Evaluation - MSE: {mse:.4f}, MAE: {mae:.4f}, R²: {r2:.4f}")

    except Exception as e:
        logging.error("An error occurred during model evaluation", exc_info=True)

# 示例使用
if __name__ == "__main__":
    from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
    import numpy as np

    # 假设真实值和预测值
    y_true = np.array([120, 130, 128, 132, 135])
    y_pred = np.array([118, 131, 130, 129, 136])

    # 设置日志
    setup_logging()

    # 记录模型评估
    log_model_evaluation(y_true, y_pred)
```

### 3. 在主程序中调用

在主程序中调用日志记录功能，可以方便地记录每次模型评估的结果，例如在`main.py`中：

```python
from logging_setup import setup_logging, log_model_evaluation

def main():
    # 假设真实值和预测值
    y_true = np.array([120, 130, 128, 132, 135])
    y_pred = np.array([118, 131, 130, 129, 136])

    # 设置日志
    setup_logging()

    # 记录模型评估
    log_model_evaluation(y_true, y_pred)

if __name__ == "__main__":
    main()
```

### 总结

通过有效的日志记录和错误监控，可以在模型开发和部署过程中，及时捕捉和处理异常情况。这对于提高模型的可靠性和可维护性非常重要。

如果你对日志记录的具体实现或其他相关问题有进一步的疑问，请随时联系我！

---
第八段代码实现了血压预测模型的优化，主要使用了随机森林回归器，并通过数据预处理、模型管道和可视化来评估模型性能。以下是代码的详细分析及一些优化建议。

### 1. 功能分析

- **数据读取与清理**：
  - 使用 `pandas` 读取清洗后的血压数据，并检查文件是否存在。
  - 清理列名以去除多余的空格，确保后续处理中的列名准确。

- **特征选择**：
  - 从数据中删除目标变量（收缩压和舒张压），将其他特征分配给 `X` 和 `y`。
  - 定义类别特征和数值特征，以便在后续的预处理步骤中使用。

- **创建预处理步骤**：
  - 使用 `ColumnTransformer` 定义数值特征和类别特征的处理方式。在这里，所有特征都被直接传递，因为输入数据已被编码。

- **模型管道**：
  - 使用 `Pipeline` 创建模型管道，该管道将预处理步骤和随机森林回归模型连接在一起，以简化模型训练和评估过程。

- **训练与预测**：
  - 使用 `train_test_split` 将数据集分为训练集和测试集（80%/20%）。
  - 训练模型并进行预测。

- **评估指标**：
  - 计算收缩压（SBP）和舒张压（DBP）的R²值和均方误差（MSE），并输出结果。

- **可视化结果**：
  - 使用 `matplotlib` 绘制预测结果的散点图，帮助直观理解模型的预测性能。

### 2. 代码优化建议

为了提高代码的可读性和可维护性，可以考虑以下几点优化：

- **函数封装**：将主要步骤封装成函数，以便更好地组织代码并提高重用性。
- **异常处理**：在数据读取和处理过程中增加异常处理，以捕捉潜在的错误。
- **参数化**：将一些硬编码的参数（如文件路径、测试集比例等）参数化，使得代码更灵活。

以下是经过优化的代码示例：

```python
import pandas as pd
import os
from sklearn.model_selection import train_test_split
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import r2_score, mean_squared_error
import matplotlib.pyplot as plt
import matplotlib

def load_data(file_path):
    """加载数据并进行清理"""
    if os.path.exists(file_path):
        data = pd.read_csv(file_path)
        data.columns = data.columns.str.strip()  # 清理列名
        return data
    else:
        raise FileNotFoundError(f"文件不存在: {file_path}")

def preprocess_data(data):
    """预处理数据"""
    X = data.drop(columns=['SBP (mmHg)', 'DBP (mmHg)'])
    y = data[['SBP (mmHg)', 'DBP (mmHg)']]
    return X, y

def build_model_pipeline(numeric_features, categorical_features):
    """构建模型管道"""
    preprocessor = ColumnTransformer(
        transformers=[
            ('num', 'passthrough', numeric_features),
            ('cat', 'passthrough', categorical_features)
        ])
    
    model_pipeline = Pipeline(steps=[
        ('preprocessor', preprocessor),
        ('model', RandomForestRegressor(random_state=42))
    ])
    
    return model_pipeline

def evaluate_model(model, X_test, y_test):
    """评估模型性能"""
    y_pred = model.predict(X_test)
    r2_sbp = r2_score(y_test['SBP (mmHg)'], y_pred[:, 0])
    r2_dbp = r2_score(y_test['DBP (mmHg)'], y_pred[:, 1])
    mse_sbp = mean_squared_error(y_test['SBP (mmHg)'], y_pred[:, 0])
    mse_dbp = mean_squared_error(y_test['DBP (mmHg)'], y_pred[:, 1])

    print(f"SBP R²: {r2_sbp}, MSE: {mse_sbp}")
    print(f"DBP R²: {r2_dbp}, MSE: {mse_dbp}")

    return y_pred

def plot_results(y_test, y_pred):
    """绘制预测结果"""
    plt.figure(figsize=(12, 5))

    # SBP 结果
    plt.subplot(1, 2, 1)
    plt.scatter(y_test['SBP (mmHg)'], y_pred[:, 0])
    plt.plot([y_test['SBP (mmHg)'].min(), y_test['SBP (mmHg)'].max()],
             [y_test['SBP (mmHg)'].min(), y_test['SBP (mmHg)'].max()], color='red', lw=2)
    plt.xlabel('实际 SBP (mmHg)')
    plt.ylabel('预测 SBP (mmHg)')
    plt.title('SBP 预测结果')

    # DBP 结果
    plt.subplot(1, 2, 2)
    plt.scatter(y_test['DBP (mmHg)'], y_pred[:, 1])
    plt.plot([y_test['DBP (mmHg)'].min(), y_test['DBP (mmHg)'].max()],
             [y_test['DBP (mmHg)'].min(), y_test['DBP (mmHg)'].max()], color='red', lw=2)
    plt.xlabel('实际 DBP (mmHg)')
    plt.ylabel('预测 DBP (mmHg)')
    plt.title('DBP 预测结果')

    plt.tight_layout()
    plt.show()

def main():
    cleaned_file_path = r'D:\测试项目\pythonProject\blood_pressure_data\cleaned_blood_pressure_data.csv'
    try:
        data_cleaned = load_data(cleaned_file_path)
        print("原始列名列表:", data_cleaned.columns.tolist())
        
        # 预处理数据
        X, y = preprocess_data(data_cleaned)
        
        # 更新特征列表
        categorical_features = [...]  # 维持原有特征列表
        numeric_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()

        # 构建模型管道
        model_pipeline = build_model_pipeline(numeric_features, categorical_features)

        # 划分训练集和测试集
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

        # 训练模型
        model_pipeline.fit(X_train, y_train)

        # 评估模型
        y_pred = evaluate_model(model_pipeline, X_test, y_test)

        # 绘制结果
        plot_results(y_test, y_pred)

    except Exception as e:
        print(str(e))

if __name__ == "__main__":
    main()
```

### 总结

通过以上优化，代码结构更加清晰，各个模块功能明确，便于后续维护和扩展。同时，增加了异常处理，提升了代码的健壮性。这种封装和模块化的方式，特别适合较大的数据处理和模型开发项目。

如果你对模型优化或其他相关问题有进一步的疑问，请随时联系我！